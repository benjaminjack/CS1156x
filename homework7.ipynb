{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning From the Data, Homework 7\n",
    "\n",
    "## Validation\n",
    "\n",
    "In the following problems, use the data provided in the files `in.dta` and `out.dta` for Homework # 6. We are going to apply linear regression with a nonlinear transformation for classification (without regularization). The nonlinear transformation is given by $\\phi_0$ through $\\phi_7$ which transform $(x_1, x_2)$ into\n",
    "\n",
    "$1 \\qquad x_1 \\qquad x_2 \\qquad x_1^2 \\qquad x_2^2 \\qquad x_1x_2 \\qquad |x_1 - x_2| \\qquad |x_1 + x_2|$\n",
    "\n",
    "To illustrate how taking out points for validation affects the performance, we will consider the hypotheses trained on $\\mathcal{D}_\\text{train}$ (without restoring the full $\\mathcal{D}$ for training after validation is done).\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "Split `in.dta` into training (first 25 examples) and validation (last 10 examples). Train on the 25 examples only, using the validation set of the 10 examples to select between five models that apply linear regression $\\phi_0$ through $\\phi_k$, with $k = 3, 4, 5, 6, 7$. For which model is the classification error on the validation set smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (0.44, 0.29999999999999999)\n",
      "4 (0.32000000000000001, 0.5)\n",
      "5 (0.080000000000000002, 0.20000000000000001)\n",
      "6 (0.040000000000000001, 0.0)\n",
      "7 (0.040000000000000001, 0.10000000000000001)\n"
     ]
    }
   ],
   "source": [
    "def transform_data(X1, X2, k=7):\n",
    "    Z = np.column_stack((np.ones(X1.shape), \n",
    "                     X1, \n",
    "                     X2, \n",
    "                     X1**2, \n",
    "                     X2**2,\n",
    "                     X1*X2,\n",
    "                     np.abs(X1 - X2),\n",
    "                     np.abs(X1 + X2)))\n",
    "    return Z[:, 0:k+1]\n",
    "\n",
    "def linear_regression(data, W=None, lamd=0, k=7):\n",
    "    # Extract and transform data\n",
    "    X1 = data[:,0]\n",
    "    X2 = data[:,1]\n",
    "    Y = data[:,[2]]\n",
    "    \n",
    "    Z = transform_data(X1, X2, k=k)\n",
    "\n",
    "    # Compute W if not given\n",
    "    if W is None:\n",
    "        Z_square = np.dot(Z.T, Z)\n",
    "        W = np.dot(np.linalg.inv(Z_square + np.identity(Z_square.shape[0])*lamd), np.dot(Z.T, Y))\n",
    "\n",
    "    \n",
    "    Y_hat = np.sign(np.dot(W.T, Z.T))\n",
    "    error = np.sum(Y_hat.T != Y)/Y.shape[0]\n",
    "    return error, W\n",
    "\n",
    "def run_regression(train, test, lamd=0, k=7):\n",
    "    # Compute E_in and E_out\n",
    "    E_in, W_lin = linear_regression(train, lamd=lamd, k=k)\n",
    "    E_out, _ = linear_regression(test, W=W_lin, k=k)\n",
    "    return E_in, E_out\n",
    "\n",
    "def run_experiment(train, test):\n",
    "    for k in range(3,8):\n",
    "        print(k, run_regression(train, test, k=k))\n",
    "\n",
    "# Read in data\n",
    "train = pd.read_table(\"http://work.caltech.edu/data/in.dta\", delim_whitespace=True, header=None).values\n",
    "test = pd.read_table(\"http://work.caltech.edu/data/out.dta\", delim_whitespace=True, header=None).values\n",
    "\n",
    "D_train = train[0:25, :]\n",
    "D_val = train[25:, :]\n",
    "D_test = test\n",
    "\n",
    "run_experiment(D_train, D_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [**d**] $k=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "Evaluate the out-of-sample classification error using `out.dta` on the 5 models to see how well the validation set predicted the best of the 5 models. For which model is the out-of-sample classification error smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (0.44, 0.41999999999999998)\n",
      "4 (0.32000000000000001, 0.41599999999999998)\n",
      "5 (0.080000000000000002, 0.188)\n",
      "6 (0.040000000000000001, 0.084000000000000005)\n",
      "7 (0.040000000000000001, 0.071999999999999995)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(D_train, D_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [**e**] $k=7$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Reverse the role of training and validation sets; now training with the last 10 examples and validating with the first 25 examples. For which model is the classification error on the validation set smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (0.40000000000000002, 0.28000000000000003)\n",
      "4 (0.29999999999999999, 0.35999999999999999)\n",
      "5 (0.20000000000000001, 0.20000000000000001)\n",
      "6 (0.0, 0.080000000000000002)\n",
      "7 (0.0, 0.12)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(D_val, D_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [**d**] $k=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "\n",
    "Once again, evaluate the out-of-sample classification error using `out.dta` on the 5 models to see how well the validation set predicted the best of the 5 models. For which model is the out-of-sample classifcation error smallest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (0.40000000000000002, 0.39600000000000002)\n",
      "4 (0.29999999999999999, 0.38800000000000001)\n",
      "5 (0.20000000000000001, 0.28399999999999997)\n",
      "6 (0.0, 0.192)\n",
      "7 (0.0, 0.19600000000000001)\n"
     ]
    }
   ],
   "source": [
    "run_experiment(D_val, D_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [**d**] $k=6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "\n",
    "What values are closest in Euclidean distance to the out-of-sample classification error obtained for the model chosen in Problems 1 and 3, respectively?\n",
    "\n",
    "`0.072`, `0.192`\n",
    "\n",
    "Answer: [**b**] 0.1, 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Bias\n",
    "\n",
    "### Problem 6\n",
    "\n",
    "Let $e_1$ and $e_2$ be independent random variables, distributed uniformly over the interval $[0,1]$. Let $e = \\min(e_1, e_2)$. The expected values of $e_1, e_2, e$ are closest to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.49905187  0.50138884  0.33330751]\n"
     ]
    }
   ],
   "source": [
    "# Generate 100000 pairs of e_1 and e_2\n",
    "e = np.random.rand(100000,2)\n",
    "# Take minimum of e_1 and e_2\n",
    "e_min = np.min(e, axis=1)\n",
    "e = np.column_stack((e, e_min))\n",
    "# Compute mean\n",
    "print(np.mean(e, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: [**d**] 0.5, 0.5, 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "### Problem 7\n",
    "\n",
    "You are given the data points $(x, y): (-1, 0), (\\rho, 1), (1, 0), \\rho \\geq 0$, and a choice between two models: constant $\\{h_0(x) = b\\}$ and linear $\\{h_1(x) = ax + b\\}$. For which value of $\\rho$ would the two models be tied using leave-one-out cross-validation with the squared error measure?\n",
    "\n",
    "Total error for $h_0 = \\frac{3}{2}$\n",
    "\n",
    "Total error for $h_1 = \\left(\\frac{2}{(\\rho+1)}\\right)^2 + \\left(\\frac{-2}{(\\rho-1)}\\right)^2 + 1$\n",
    "\n",
    "Set the two equal to each other and solve for $\\rho$:\n",
    "\n",
    "$\\left(\\frac{2}{(\\rho+1)}\\right)^2 + \\left(\\frac{-2}{(\\rho-1)}\\right)^2 + 1 = \\frac{3}{2}$\n",
    "\n",
    "Go ahead and use wolfram alpha to solve this analytically...\n",
    "\n",
    "Answer: [**c**] $\\sqrt{9+4\\sqrt{6}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLA vs. SVM\n",
    "\n",
    "In the following problems, we compare PLA to SVM with hard margin on linearly separable data sets. For each run, you will create your own target function $f$ and data set $\\mathcal{D}$. Take $d = 2$ and choose a random line in the plane as your target function $f$ (do this by takking two random, uniformly distributed points on $[-1,1] \\times [-1, 1]$ and taking the line passing through them), where one side of the line maps to +1 and the other maps to -1. Choose the inputs $\\mathbf{x}_n$ of the data set as random points in $\\mathcal{X} = [-1,1] \\times [-1, 1]$, and evaluate the target function on each $\\mathbf{x}_n$ to get the corresponding output $y_n$. If all data points are on the side of the line, discard the run and start a new run.\n",
    "\n",
    "Start PLA with the all-zero vector and pick the misclassified point for each PLA iteration at random. Run PLA to find the final hypothesis $g_\\text{PLA}$ and measure the disagreement between $f$ and $g_\\text{PLA}$ as $\\mathbb{P}[f(\\mathbf{x}) \\neq g_\\text{PLA}(\\mathbf{x})]$ (you can either calculate this exactly, or approximate it by generating a sufficiently large, separate set of points to evaluate it). Now, run SVM on the same data to find the final hypothesis $g_\\text{SVM}$ by solving\n",
    "\n",
    "$\\min_{\\mathbf{w},b} \\qquad \\frac{1}{2}\\mathbf{w}^T\\mathbf{w}$\n",
    "\n",
    "$\\text{s.t.} \\qquad y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1$\n",
    "\n",
    "using quadratic programming on the primal or the dual problem, or using an SVM package. Measure the disagreement between $f$ and $g_\\text{SVM}$ as $\\mathbb{P}[f(\\mathbf{x}) \\neq g_\\text{SVM}(\\mathbf{x})]$, and count the number of support vectors you get in each run.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 10 (0.621, 2.8359999999999999)\n",
      "N = 100 (0.625, 2.9980000000000002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def generate_line():\n",
    "    x_rand = np.random.uniform(-1, 1, size=(2,2))\n",
    "    slope = (x_rand[0,1] - x_rand[0,0])/(x_rand[1,1] - x_rand[1,0])\n",
    "    intercept = x_rand[0,1] - slope*x_rand[1,1]\n",
    "    W_true = np.array([[intercept], [slope], [-1]])\n",
    "    return W_true\n",
    "\n",
    "def generate_points(W_true, N=100):\n",
    "    ones = np.ones((1, N))\n",
    "    X = np.vstack((ones, np.random.uniform(-1,1, size=(2,N))))\n",
    "    Y = np.sign(np.dot(W_true.T, X)).T\n",
    "    if np.all(Y == -1) or np.all(Y == 1):\n",
    "        return generate_points(W_true, N)\n",
    "    return X, Y\n",
    "\n",
    "def run_pla(X, Y):\n",
    "    W = np.zeros((3,1))\n",
    "    Y_hat = np.sign(np.dot(W.T,X)).T\n",
    "    missed = np.where(Y_hat != Y)[0]\n",
    "    while missed.shape[0] > 0:\n",
    "        sel = np.random.choice(missed)\n",
    "        X_sel = X.T[[sel],:]\n",
    "        Y_sel = Y[[sel],:]\n",
    "        W = W + Y_sel*X_sel.T\n",
    "        Y_hat = np.sign(np.dot(W.T,X)).T\n",
    "        missed = np.where(Y_hat != Y)[0]\n",
    "    return W\n",
    "\n",
    "def estimate_e_out(W_true, W_pred, svm):\n",
    "    X, Y = generate_points(W_true, N=10000)\n",
    "    Y_hat = np.sign(np.dot(W_pred.T, X)).T\n",
    "    pla_error = np.sum(Y_hat != Y)/10000\n",
    "    svm_preds = svm.predict(X.T).reshape(10000,1)\n",
    "    svm_error = np.sum(svm_preds != Y)/10000\n",
    "    return pla_error, svm_error\n",
    "\n",
    "def run_experiment(points = 10, trials = 1000):\n",
    "    counts = np.zeros(1000)\n",
    "    support = np.zeros(1000)\n",
    "    for i in range(1000):\n",
    "        W_true = generate_line()\n",
    "        X, Y = generate_points(W_true, N=points)\n",
    "        W_pred = run_pla(X, Y)\n",
    "        svm = SVC(kernel='linear', C=np.inf)\n",
    "        svm.fit(X.T, Y.ravel())\n",
    "        pla_error, svm_error = estimate_e_out(W_true, W_pred, svm)\n",
    "        counts[i] = svm_error < pla_error\n",
    "        support[i] = np.sum(svm.n_support_)\n",
    "    return np.sum(counts)/1000, np.sum(support)/1000\n",
    "\n",
    "print(\"N = 10\", run_experiment())\n",
    "print(\"N = 100\", run_experiment(points=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 8\n",
    "\n",
    "Answer: [**c**] 60%\n",
    "\n",
    "### Problem 9\n",
    "\n",
    "Answer: [**d**] 65%\n",
    "\n",
    "### Problem 10\n",
    "\n",
    "Answer: [**b**] 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
